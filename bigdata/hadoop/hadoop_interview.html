<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Hadoop面试题 | yx91490的博客</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="icon" href="/logo.png">
    <script async="true" src="https://www.googletagmanager.com/gtag/js?id=G-QQHZM2VLM0"></script>
    <script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-QQHZM2VLM0');</script>
    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?6781d2ac2dff1f3b278518419b4d4deb";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>
    <meta name="description" content="java, 大数据(hadoop, sqoop, kylin, zeppelin)相关技术, 工作经验记录">
    <meta name="google-site-verification" content="j1Gm2ZeMV3D7mPiI08fpx91dEOSlhCAJjD4vy_pSroQ">
    <meta name="baidu-site-verification" content="4z2bGbjYMB">
    
    <link rel="preload" href="/assets/css/0.styles.003598ab.css" as="style"><link rel="preload" href="/assets/js/app.e1b640f1.js" as="script"><link rel="preload" href="/assets/js/2.f106ac60.js" as="script"><link rel="preload" href="/assets/js/53.24880467.js" as="script"><link rel="prefetch" href="/assets/js/10.c8f220ae.js"><link rel="prefetch" href="/assets/js/100.f3b396a9.js"><link rel="prefetch" href="/assets/js/101.a2f089a9.js"><link rel="prefetch" href="/assets/js/102.2b7c6ac9.js"><link rel="prefetch" href="/assets/js/103.0b180d5d.js"><link rel="prefetch" href="/assets/js/104.b032df8c.js"><link rel="prefetch" href="/assets/js/105.b1484738.js"><link rel="prefetch" href="/assets/js/106.88d0b196.js"><link rel="prefetch" href="/assets/js/107.94e09d18.js"><link rel="prefetch" href="/assets/js/108.6c5ede1e.js"><link rel="prefetch" href="/assets/js/109.32507b63.js"><link rel="prefetch" href="/assets/js/11.6a0d3e99.js"><link rel="prefetch" href="/assets/js/110.7451ea02.js"><link rel="prefetch" href="/assets/js/111.57fcb339.js"><link rel="prefetch" href="/assets/js/112.85d6f6fb.js"><link rel="prefetch" href="/assets/js/113.075e3c78.js"><link rel="prefetch" href="/assets/js/114.004b1ec1.js"><link rel="prefetch" href="/assets/js/115.c689cdf3.js"><link rel="prefetch" href="/assets/js/116.4169f9ba.js"><link rel="prefetch" href="/assets/js/117.3814b9ae.js"><link rel="prefetch" href="/assets/js/118.0388d1ec.js"><link rel="prefetch" href="/assets/js/119.351bbbb1.js"><link rel="prefetch" href="/assets/js/12.f5f20270.js"><link rel="prefetch" href="/assets/js/120.5bedd5a9.js"><link rel="prefetch" href="/assets/js/121.64055faf.js"><link rel="prefetch" href="/assets/js/122.2c253004.js"><link rel="prefetch" href="/assets/js/123.1805544a.js"><link rel="prefetch" href="/assets/js/124.1cff00de.js"><link rel="prefetch" href="/assets/js/125.994e97be.js"><link rel="prefetch" href="/assets/js/126.ecfded98.js"><link rel="prefetch" href="/assets/js/127.52fc6d84.js"><link rel="prefetch" href="/assets/js/128.4b13ff7a.js"><link rel="prefetch" href="/assets/js/129.908dadab.js"><link rel="prefetch" href="/assets/js/13.e4068e14.js"><link rel="prefetch" href="/assets/js/130.be48dae0.js"><link rel="prefetch" href="/assets/js/131.bb94529c.js"><link rel="prefetch" href="/assets/js/132.719ea7a4.js"><link rel="prefetch" href="/assets/js/133.1571d90c.js"><link rel="prefetch" href="/assets/js/134.28317a56.js"><link rel="prefetch" href="/assets/js/135.737f47ca.js"><link rel="prefetch" href="/assets/js/136.a07c98d2.js"><link rel="prefetch" href="/assets/js/137.0247ffa3.js"><link rel="prefetch" href="/assets/js/138.b1bc859b.js"><link rel="prefetch" href="/assets/js/139.c717f53d.js"><link rel="prefetch" href="/assets/js/14.d495a1fa.js"><link rel="prefetch" href="/assets/js/140.d7e37de8.js"><link rel="prefetch" href="/assets/js/141.56bf3834.js"><link rel="prefetch" href="/assets/js/142.c612c38d.js"><link rel="prefetch" href="/assets/js/143.de9d2fdb.js"><link rel="prefetch" href="/assets/js/144.9be6f85e.js"><link rel="prefetch" href="/assets/js/145.f64bef18.js"><link rel="prefetch" href="/assets/js/146.af11c5d1.js"><link rel="prefetch" href="/assets/js/147.90167410.js"><link rel="prefetch" href="/assets/js/148.120b8aa9.js"><link rel="prefetch" href="/assets/js/149.2135d5d7.js"><link rel="prefetch" href="/assets/js/15.f6b86d5b.js"><link rel="prefetch" href="/assets/js/150.9f5222ae.js"><link rel="prefetch" href="/assets/js/151.137366cc.js"><link rel="prefetch" href="/assets/js/152.33f96cd7.js"><link rel="prefetch" href="/assets/js/153.532b6d63.js"><link rel="prefetch" href="/assets/js/154.20d9afb2.js"><link rel="prefetch" href="/assets/js/155.4cae8696.js"><link rel="prefetch" href="/assets/js/156.cfbbbd28.js"><link rel="prefetch" href="/assets/js/157.2e5d85b2.js"><link rel="prefetch" href="/assets/js/158.4071d9dd.js"><link rel="prefetch" href="/assets/js/159.f3a4abbf.js"><link rel="prefetch" href="/assets/js/16.816ca34d.js"><link rel="prefetch" href="/assets/js/160.8e34ba8c.js"><link rel="prefetch" href="/assets/js/161.0269d7b8.js"><link rel="prefetch" href="/assets/js/162.b353dc0e.js"><link rel="prefetch" href="/assets/js/163.9e418b12.js"><link rel="prefetch" href="/assets/js/164.3f031ead.js"><link rel="prefetch" href="/assets/js/165.67deb69a.js"><link rel="prefetch" href="/assets/js/166.fa2c1df9.js"><link rel="prefetch" href="/assets/js/167.8c3c0982.js"><link rel="prefetch" href="/assets/js/168.ad97dab7.js"><link rel="prefetch" href="/assets/js/169.bb37c018.js"><link rel="prefetch" href="/assets/js/17.fdc3dfd9.js"><link rel="prefetch" href="/assets/js/170.3c2ae219.js"><link rel="prefetch" href="/assets/js/171.5bbb7941.js"><link rel="prefetch" href="/assets/js/172.feb2614d.js"><link rel="prefetch" href="/assets/js/173.74197b24.js"><link rel="prefetch" href="/assets/js/174.42f6c966.js"><link rel="prefetch" href="/assets/js/175.7ac324cf.js"><link rel="prefetch" href="/assets/js/176.59a5d441.js"><link rel="prefetch" href="/assets/js/177.51156d34.js"><link rel="prefetch" href="/assets/js/178.77315afc.js"><link rel="prefetch" href="/assets/js/179.0285d2a2.js"><link rel="prefetch" href="/assets/js/18.b7d67b50.js"><link rel="prefetch" href="/assets/js/180.59e179ad.js"><link rel="prefetch" href="/assets/js/181.88c1d3eb.js"><link rel="prefetch" href="/assets/js/182.cd354389.js"><link rel="prefetch" href="/assets/js/183.91439d0b.js"><link rel="prefetch" href="/assets/js/184.db21183e.js"><link rel="prefetch" href="/assets/js/185.b9f24dc7.js"><link rel="prefetch" href="/assets/js/186.9f4defed.js"><link rel="prefetch" href="/assets/js/187.21f4a27b.js"><link rel="prefetch" href="/assets/js/188.eb07e45e.js"><link rel="prefetch" href="/assets/js/189.3859788d.js"><link rel="prefetch" href="/assets/js/19.29c9fd25.js"><link rel="prefetch" href="/assets/js/190.4bb0da86.js"><link rel="prefetch" href="/assets/js/191.3951b40b.js"><link rel="prefetch" href="/assets/js/192.6c5f0cca.js"><link rel="prefetch" href="/assets/js/193.bfb50c9b.js"><link rel="prefetch" href="/assets/js/194.3492f53d.js"><link rel="prefetch" href="/assets/js/195.d68458ca.js"><link rel="prefetch" href="/assets/js/196.ce147ef8.js"><link rel="prefetch" href="/assets/js/197.5cbf5b23.js"><link rel="prefetch" href="/assets/js/198.84823399.js"><link rel="prefetch" href="/assets/js/199.68e1ad5b.js"><link rel="prefetch" href="/assets/js/20.d075c66d.js"><link rel="prefetch" href="/assets/js/200.28228f8f.js"><link rel="prefetch" href="/assets/js/201.cb2b1b03.js"><link rel="prefetch" href="/assets/js/202.ba47867a.js"><link rel="prefetch" href="/assets/js/203.40df826d.js"><link rel="prefetch" href="/assets/js/204.a7acca65.js"><link rel="prefetch" href="/assets/js/21.570ce9dd.js"><link rel="prefetch" href="/assets/js/22.dfaa22bd.js"><link rel="prefetch" href="/assets/js/23.763897cc.js"><link rel="prefetch" href="/assets/js/24.5ed69425.js"><link rel="prefetch" href="/assets/js/25.acbc0566.js"><link rel="prefetch" href="/assets/js/26.11a06d5c.js"><link rel="prefetch" href="/assets/js/27.ab1d83bf.js"><link rel="prefetch" href="/assets/js/28.2c7fa6b0.js"><link rel="prefetch" href="/assets/js/29.4f082b0e.js"><link rel="prefetch" href="/assets/js/3.88314f1f.js"><link rel="prefetch" href="/assets/js/30.4f2dbc67.js"><link rel="prefetch" href="/assets/js/31.8be81ae4.js"><link rel="prefetch" href="/assets/js/32.b2b2449c.js"><link rel="prefetch" href="/assets/js/33.5aeead46.js"><link rel="prefetch" href="/assets/js/34.c570d89d.js"><link rel="prefetch" href="/assets/js/35.bfefaccf.js"><link rel="prefetch" href="/assets/js/36.e27ef041.js"><link rel="prefetch" href="/assets/js/37.81de3fc6.js"><link rel="prefetch" href="/assets/js/38.e445ebf4.js"><link rel="prefetch" href="/assets/js/39.aabf15c0.js"><link rel="prefetch" href="/assets/js/4.06220ca6.js"><link rel="prefetch" href="/assets/js/40.c65bcc4b.js"><link rel="prefetch" href="/assets/js/41.2678034d.js"><link rel="prefetch" href="/assets/js/42.394bab4b.js"><link rel="prefetch" href="/assets/js/43.c1025883.js"><link rel="prefetch" href="/assets/js/44.3c92e738.js"><link rel="prefetch" href="/assets/js/45.09352f0a.js"><link rel="prefetch" href="/assets/js/46.a29da346.js"><link rel="prefetch" href="/assets/js/47.d7c34b33.js"><link rel="prefetch" href="/assets/js/48.d6d0e7e9.js"><link rel="prefetch" href="/assets/js/49.8f33bee6.js"><link rel="prefetch" href="/assets/js/5.aad0f8a0.js"><link rel="prefetch" href="/assets/js/50.191eb353.js"><link rel="prefetch" href="/assets/js/51.183390f3.js"><link rel="prefetch" href="/assets/js/52.33cf3b64.js"><link rel="prefetch" href="/assets/js/54.1ca92df0.js"><link rel="prefetch" href="/assets/js/55.3866223c.js"><link rel="prefetch" href="/assets/js/56.72514a51.js"><link rel="prefetch" href="/assets/js/57.39dc2ff1.js"><link rel="prefetch" href="/assets/js/58.6192b2fa.js"><link rel="prefetch" href="/assets/js/59.2a297e97.js"><link rel="prefetch" href="/assets/js/6.b30ad2af.js"><link rel="prefetch" href="/assets/js/60.72b6f761.js"><link rel="prefetch" href="/assets/js/61.413fb100.js"><link rel="prefetch" href="/assets/js/62.bdeb7cc5.js"><link rel="prefetch" href="/assets/js/63.f43a012d.js"><link rel="prefetch" href="/assets/js/64.25ae3b65.js"><link rel="prefetch" href="/assets/js/65.f40991de.js"><link rel="prefetch" href="/assets/js/66.890a4d07.js"><link rel="prefetch" href="/assets/js/67.22c07eb9.js"><link rel="prefetch" href="/assets/js/68.ef8c05fe.js"><link rel="prefetch" href="/assets/js/69.6b4a28f7.js"><link rel="prefetch" href="/assets/js/7.9797e790.js"><link rel="prefetch" href="/assets/js/70.99c24e1e.js"><link rel="prefetch" href="/assets/js/71.88bf09bb.js"><link rel="prefetch" href="/assets/js/72.e38fc535.js"><link rel="prefetch" href="/assets/js/73.20c40b1f.js"><link rel="prefetch" href="/assets/js/74.27d89967.js"><link rel="prefetch" href="/assets/js/75.e6b3efb9.js"><link rel="prefetch" href="/assets/js/76.d8980109.js"><link rel="prefetch" href="/assets/js/77.0607f650.js"><link rel="prefetch" href="/assets/js/78.a02b3eea.js"><link rel="prefetch" href="/assets/js/79.d3e9dc2c.js"><link rel="prefetch" href="/assets/js/8.291f88d1.js"><link rel="prefetch" href="/assets/js/80.a5dd5cd5.js"><link rel="prefetch" href="/assets/js/81.ee830613.js"><link rel="prefetch" href="/assets/js/82.203c2e9e.js"><link rel="prefetch" href="/assets/js/83.1f03d3bb.js"><link rel="prefetch" href="/assets/js/84.00420868.js"><link rel="prefetch" href="/assets/js/85.03d28b8c.js"><link rel="prefetch" href="/assets/js/86.222a2cbb.js"><link rel="prefetch" href="/assets/js/87.e1225539.js"><link rel="prefetch" href="/assets/js/88.9083b84b.js"><link rel="prefetch" href="/assets/js/89.cccfc7f2.js"><link rel="prefetch" href="/assets/js/9.00ac3fcb.js"><link rel="prefetch" href="/assets/js/90.e80b164d.js"><link rel="prefetch" href="/assets/js/91.1d877fdd.js"><link rel="prefetch" href="/assets/js/92.f0046ee7.js"><link rel="prefetch" href="/assets/js/93.282fae3e.js"><link rel="prefetch" href="/assets/js/94.20acd58b.js"><link rel="prefetch" href="/assets/js/95.2091f5d3.js"><link rel="prefetch" href="/assets/js/96.c814193d.js"><link rel="prefetch" href="/assets/js/97.07750c92.js"><link rel="prefetch" href="/assets/js/98.de88f11e.js"><link rel="prefetch" href="/assets/js/99.21104852.js">
    <link rel="stylesheet" href="/assets/css/0.styles.003598ab.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">yx91490的博客</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/java/" class="nav-link">
  Java开发
</a></div><div class="nav-item"><a href="/bigdata/" class="nav-link router-link-active">
  大数据
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="contactMe" class="dropdown-title"><span class="title">其他</span> <span class="arrow down"></span></button> <button type="button" aria-label="contactMe" class="mobile-dropdown-title"><span class="title">其他</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/sql/" class="nav-link">
  SQL
</a></li><li class="dropdown-item"><!----> <a href="/linux/" class="nav-link">
  Linux
</a></li><li class="dropdown-item"><!----> <a href="/clang/" class="nav-link">
  C语言
</a></li><li class="dropdown-item"><!----> <a href="/python/" class="nav-link">
  Python
</a></li><li class="dropdown-item"><!----> <a href="/diagram/" class="nav-link">
  图示速查
</a></li><li class="dropdown-item"><!----> <a href="/collection/" class="nav-link">
  资料收藏
</a></li><li class="dropdown-item"><!----> <a href="/cs/" class="nav-link">
  计算机科学
</a></li><li class="dropdown-item"><!----> <a href="https://github.com/yx91490" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://github.com/yx91490/yx91490.github.io/issues/new" target="_blank" rel="noopener noreferrer" class="nav-link external">
  给我留言
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/java/" class="nav-link">
  Java开发
</a></div><div class="nav-item"><a href="/bigdata/" class="nav-link router-link-active">
  大数据
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="contactMe" class="dropdown-title"><span class="title">其他</span> <span class="arrow down"></span></button> <button type="button" aria-label="contactMe" class="mobile-dropdown-title"><span class="title">其他</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/sql/" class="nav-link">
  SQL
</a></li><li class="dropdown-item"><!----> <a href="/linux/" class="nav-link">
  Linux
</a></li><li class="dropdown-item"><!----> <a href="/clang/" class="nav-link">
  C语言
</a></li><li class="dropdown-item"><!----> <a href="/python/" class="nav-link">
  Python
</a></li><li class="dropdown-item"><!----> <a href="/diagram/" class="nav-link">
  图示速查
</a></li><li class="dropdown-item"><!----> <a href="/collection/" class="nav-link">
  资料收藏
</a></li><li class="dropdown-item"><!----> <a href="/cs/" class="nav-link">
  计算机科学
</a></li><li class="dropdown-item"><!----> <a href="https://github.com/yx91490" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://github.com/yx91490/yx91490.github.io/issues/new" target="_blank" rel="noopener noreferrer" class="nav-link external">
  给我留言
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Zeppelin</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/bigdata/zeppelin/heart_diease_dataset.html" class="sidebar-link">心脏病预测数据</a></li><li><a href="/bigdata/zeppelin/zeppelin_bugs.html" class="sidebar-link">zeppelin使用趟坑</a></li><li><a href="/bigdata/zeppelin/zeppelin_sharding.html" class="sidebar-link">Zeppelin v0.8分片方案</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Waterdrop</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/bigdata/waterdrop/waterdrop.html" class="sidebar-link">Waterdrop学习笔记</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Kylin</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/bigdata/kylin/awesome_kylin.html" class="sidebar-link">Kylin学习资料汇总</a></li><li><a href="/bigdata/kylin/read_kylin_source.html" class="sidebar-link">阅读Kylin源码</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Sqoop</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/bigdata/sqoop/sqoop_usage.html" class="sidebar-link">代码调试</a></li><li><a href="/bigdata/sqoop/sqoop_hcatalog.html" class="sidebar-link">sqoopHCatalog使用</a></li><li><a href="/bigdata/sqoop/sqoop_mysql_temp_file.html" class="sidebar-link">sqoop导入导致MySQL产生大临时文件问题排查</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>ZooKeeper</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/bigdata/zookeeper/zookeeper.html" class="sidebar-link">ZooKeeper笔记</a></li><li><a href="/bigdata/zookeeper/zookeeper_user.html" class="sidebar-link">ZooKeeper管理员指南</a></li><li><a href="/bigdata/zookeeper/zk_distribute_lock.html" class="sidebar-link">zookeeper实现分布式锁</a></li><li><a href="/bigdata/zookeeper/isbn9787111524311_note.html" class="sidebar-link">《ZooKeeper分布式过程协同技术详解》笔记</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>Hadoop</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/bigdata/hadoop/hadoop_interview.html" aria-current="page" class="active sidebar-link">Hadoop面试题</a></li><li><a href="/bigdata/hadoop/port.html" class="sidebar-link">Hadoop默认端口</a></li><li><a href="/bigdata/hadoop/hdfs_user.html" class="sidebar-link">HDFS命令笔记</a></li><li><a href="/bigdata/hadoop/hdfs_issue.html" class="sidebar-link">HDFS Issue</a></li><li><a href="/bigdata/hadoop/distcp.html" class="sidebar-link">Distcp命令</a></li><li><a href="/bigdata/hadoop/columnar_storage_parquet_orc.html" class="sidebar-link">列式存储（parquet,orc）</a></li><li><a href="/bigdata/hadoop/avro_specification_1.8.1.html" class="sidebar-link">avro格式规范1.8.1翻译</a></li><li><a href="/bigdata/hadoop/yarn.html" class="sidebar-link">Yarn</a></li><li><a href="/bigdata/hadoop/yarn_cli.html" class="sidebar-link">Yarn Cli命令</a></li><li><a href="/bigdata/hadoop/mapreduce.html" class="sidebar-link">MapReduce</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Hive</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/bigdata/hive/hive_cli.html" class="sidebar-link">Beeline命令行</a></li><li><a href="/bigdata/hive/hive_src.html" class="sidebar-link">Hive源码分析</a></li><li><a href="/bigdata/hive/hive_ql.html" class="sidebar-link">HiveQL</a></li><li><a href="/bigdata/hive/hive_data_type.html" class="sidebar-link">Hive数据类型</a></li><li><a href="/bigdata/hive/hive_bucket.html" class="sidebar-link">Hive分桶</a></li><li><a href="/bigdata/hive/hive_principle.html" class="sidebar-link">Hive原理</a></li><li><a href="/bigdata/hive/hive_optimize.html" class="sidebar-link">Hive优化</a></li><li><a href="/bigdata/hive/hive_parse_json.html" class="sidebar-link">Hive解析json数组</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>OLAP</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/bigdata/olap/olap.html" class="sidebar-link">OLAP笔记</a></li><li><a href="/bigdata/olap/data_analyze.html" class="sidebar-link">数据分析笔记</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>ClickHouse</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/bigdata/clickhouse/clickhouse.html" class="sidebar-link">ClickHouse学习笔记</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Doris</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/bigdata/doris/doris.html" class="sidebar-link">Doris笔记</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Kudu</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/bigdata/kudu/kudu.html" class="sidebar-link">Kudu</a></li><li><a href="/bigdata/kudu/kudu_paper.html" class="sidebar-link">Kudu: Storage for Fast Analytics on Fast Data</a></li><li><a href="/bigdata/kudu/kudu_paper_translation.html" class="sidebar-link">【译】Kudu论文</a></li><li><a href="/bigdata/kudu/kudu_note.html" class="sidebar-link">Kudu笔记</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Impala</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/bigdata/impala/cup.html" class="sidebar-link">CUP学习笔记</a></li><li><a href="/bigdata/impala/impala.html" class="sidebar-link">Impala</a></li><li><a href="/bigdata/impala/impala_admin.html" class="sidebar-link">Impala运维</a></li><li><a href="/bigdata/impala/impala_dev.html" class="sidebar-link">Impala开发笔记</a></li><li><a href="/bigdata/impala/impala_community.html" class="sidebar-link">Impala社区</a></li><li><a href="/bigdata/impala/impala_issues.html" class="sidebar-link">Impala问题记录</a></li><li><a href="/bigdata/impala/impala_paper_translation.html" class="sidebar-link">【转】【译】Impala：Hadoop上的一个现代开源SQL引擎</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Spark</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/bigdata/spark/spark.html" class="sidebar-link">Spark</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>HBase</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/bigdata/hbase/hbase_interview.html" class="sidebar-link">HBase</a></li><li><a href="/bigdata/hbase/hbase_user.html" class="sidebar-link">HBase使用</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>笔记</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/bigdata/note/oss_note.html" class="sidebar-link">《快手短视频打造高稳定千亿级别对象存储平台》笔记</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="hadoop面试题"><a href="#hadoop面试题" class="header-anchor">$</a> Hadoop面试题</h1> <h3 id="列举出hadoop中定义的最常用的inputformats-哪个是默认的"><a href="#列举出hadoop中定义的最常用的inputformats-哪个是默认的" class="header-anchor">$</a> 列举出hadoop中定义的最常用的InputFormats.哪个是默认的？</h3> <p><strong>TextInputFormat</strong>(默认)用于读取纯文本文件，key是每一行的位置偏移量，是LongWritable类型的，value是每一行的内容，为Text类型
<strong>KeyValueTextInputFormat</strong> 同样用于读取文件，如果行被分隔符（缺省是tab）分割为两部分，第一部分为key，剩下的部分 为value；如果没有分隔符，整行作为 key，value为空
<strong>SequenceFileInputFormat</strong> 用于读取sequence file。 sequence file是Hadoop用于存储数据自定义格式的binary文件。它有   两个子类：</p> <ul><li><p>SequenceFileAsBinaryInputFormat，将 key和value以BytesWritable的类型读出；</p></li> <li><p>SequenceFileAsTextInputFormat，将key和value以Text类型读出</p></li></ul> <p><strong>NLineInputFormat</strong> 可以将文件以行为单位进行split，比如文件的每一行对应一个map。得到的key是每一行                     的位置偏移量（LongWritable类型），value是每一行的内容，Text类型。
<strong>CompositeInputFormat</strong>用于多个数据源的join。
<strong>extOutputFormat</strong>，输出到纯文本文件，格式为 key + &quot; &quot; + value。
<strong>NullOutputFormat</strong>，hadoop中的/dev/null，将输出送进黑洞。
<strong>SequenceFileOutputFormat</strong>， 输出到sequence file格式文件。
<strong>MultipleSequenceFileOutputFormat</strong>，<strong>MultipleTextOutputFormat</strong>，根据key将记录输出到不同的文件。
<strong>DBInputFormat</strong>和<strong>DBOutputFormat</strong>，从DB读取，输出到DB。</p> <h3 id="textinputformat和keyvalueinputformat类不同之处在于哪里"><a href="#textinputformat和keyvalueinputformat类不同之处在于哪里" class="header-anchor">$</a> TextInputFormat和KeyValueInputFormat类不同之处在于哪里？</h3> <p>TextInputFormat读取文本文件中的所有行，提供了行的偏移作为Mapper的键，实际的行作为 mapper的值。 KeyValueInputFormat读取文本文件，解析所有行到中，首个空格前的字符是mapper的key，行的其余部分则是mapper的值。</p> <h3 id="hadoop中inputsplit是什么"><a href="#hadoop中inputsplit是什么" class="header-anchor">$</a> Hadoop中InputSplit是什么？</h3> <p>InputSplit是指分片，在MapReduce作业中，作为map task最小输入单位。分片是基于文件基础上出来的概念，通俗的理解一个文件可以切分为多少个片段，每个片段包括了&lt;文件名，开始位置，长度，位于哪些主机&gt;等信息。在    MapTask    拿到这些分片后，会知道从哪开始读取数据。</p> <h3 id="hadoop框架中文件拆分是如何被触发的"><a href="#hadoop框架中文件拆分是如何被触发的" class="header-anchor">$</a> Hadoop框架中文件拆分是如何被触发的？</h3> <p>通过运行输入格式类中的getInputSplit()方法。</p> <h3 id="考虑一种情况-map-reduce系统中-hdfs块大小是64mb-输入格式fileinputformat-有三个文件64k-65mb-127mb-那么有hadoop框架会将输入划分成多少"><a href="#考虑一种情况-map-reduce系统中-hdfs块大小是64mb-输入格式fileinputformat-有三个文件64k-65mb-127mb-那么有hadoop框架会将输入划分成多少" class="header-anchor">$</a> 考虑一种情况：Map/Reduce系统中，HDFS块大小是64MB,输入格式FileInputFormat,有三个文件64K,65MB,127MB,那么有hadoop框架会将输入划分成多少？</h3> <p>hadoop将会做5个拆分，64K文件拆分1个，65MB文件拆分2个，127MB文件拆分2个。</p> <h3 id="hadoop中的recordreader的目的是什么"><a href="#hadoop中的recordreader的目的是什么" class="header-anchor">$</a> hadoop中的RecordReader的目的是什么？</h3> <ol><li><p>以怎样的方式从分片中读取一条记录，每读取一条记录都会调用RecordReader类；</p></li> <li><p>系统默认的RecordReader是LineRecordReader，如TextInputFormat；而SequenceFileInputFormat的RecordReader是SequenceFileRecordReader；</p></li> <li><p>LineRecordReader是用每行的偏移量作为map的key，每行的内容作为map的value；</p></li> <li><p>应用场景：自定义读取每一条记录的方式；自定义读入key的类型，如希望读取的key是文件的路径或名字而不是该行在文件中的偏移量。 系统默认的LineRecordReader是按照每行的偏移量做为map输出时的key值，每行的内容作为map的value值，默认的分隔符是 回车和换行。 现在要更改map对应的输入的值，key对应的文件的路径（或者是文件名），value对应的是文件的内容 （content）。 那么我们需要重写InputFormat和RecordReader，因为RecordReader是在InputFormat中调用的，当然重写RecordReader才是重点！</p></li></ol> <h3 id="如果hadoop中没有定义定制分区-那么如何在输出到reduce前执行数据分区"><a href="#如果hadoop中没有定义定制分区-那么如何在输出到reduce前执行数据分区" class="header-anchor">$</a> 如果hadoop中没有定义定制分区，那么如何在输出到reduce前执行数据分区？</h3> <p>默认的分区器为各个键计算一个哈希值，并分配给基于这个结果的分区。</p> <h3 id="什么是combiner-举个例子-什么时候使用combiner-什么时候不用"><a href="#什么是combiner-举个例子-什么时候使用combiner-什么时候不用" class="header-anchor">$</a> 什么是Combiner?举个例子，什么时候使用combiner,什么时候不用？</h3> <p>当map生成的数据过大时，带宽就成了瓶颈，怎样精简压缩传给Reduce的数据，有不影响最终的结果呢。有一种方法就是使 用 Combiner，Combiner号称本地的Reduce，Reduce最终的输入，是Combiner的输出 Combiner的作用是把一个map产生的多个合并成一个新的,然后再将新的作为reduce的输入； 在map函数与reduce函数之间多了一个combine函数，目的是为了减少map输出的中间结果，这样减少了reduce复制map输出的数据，减少网络 传输负载； 并不是所有情况下都能使用Combiner，Combiner适用于对记录汇总的场景（如求和），但是，求平均数的场景就不能使用Combiner了。如果可以 使用Combiner，一般情况下，和我们的reduce函数是一致的。</p> <h3 id="什么是jobtracker-jobtracker有哪些特别的函数"><a href="#什么是jobtracker-jobtracker有哪些特别的函数" class="header-anchor">$</a> 什么是jobtracker? jobtracker有哪些特别的函数？</h3> <p>JobTracker是整个MapReduce计算框架中的主服务，相当于集群的“管理者”，负责整个集群的作业控制和资源管理；main（）函数</p> <h3 id="什么是tasktracker"><a href="#什么是tasktracker" class="header-anchor">$</a> 什么是tasktracker?</h3> <p>TaskTracker是JobTracker和Task之间的桥梁：一方面，从JobTracker接收并执行各种命令：运行任务、提交任务、杀死任务 等；另一方面，将本地节点上各个任务的状态通过心跳周期性汇报给JobTracker。TaskTracker与JobTracker和Task之间采用了 RPC协议进行通信。</p> <h3 id="hadoop中job和task之间是什么关系"><a href="#hadoop中job和task之间是什么关系" class="header-anchor">$</a> hadoop中job和task之间是什么关系？</h3> <ul><li><p>概述：</p> <p>Hadoop MapReduce采用Master/Slave结构。</p> <ul><li><p>Master：是整个集群的唯一的全局管理者，功能包括：作业管理、状态监控和任务调度等，即MapReduce中的JobTracker。</p></li> <li><p>Slave：负责任务的执行和任务状态的回报，即MapReduce中的TaskTracker。</p></li></ul></li> <li><p>JobTracker剖析：</p> <ul><li><p>概述：JobTracker是一个后台服务进程，启动之后，会一直监听并接收来自各个TaskTracker发送的心跳信息，包括资源使用 情况和任务运行情况等信息。</p></li> <li><p>JobTracker的主要功能：</p> <ol><li>作业控制：在hadoop中每个应用程序被表示成一个作业，每个作业又被分成多个任务，JobTracker的作业控制模块则负责作业 的分解和状态监控。</li></ol> <p>最重要的是状态监控：主要包括TaskTracker状态监控、作业状态监控和任务状态监控。主要作用：容错和为任务调度提供决 策依据。</p> <ol start="2"><li>资源管理。</li></ol></li></ul></li> <li><p>TaskTracker剖析：</p> <ul><li><p>TaskTracker概述：TaskTracker是JobTracker和Task之间的桥梁：一方面，从JobTracker接收并执行各种命令：运行任务、提交 任务、杀死任务等；另一方面，将本地节点上各个任务的状态通过心跳周期性汇报给JobTracker。TaskTracker与JobTracker和 Task之间采用了RPC协议进行通信。</p></li> <li><p>TaskTracker的功能：</p> <ol><li><p>汇报心跳：Tracker周期性将所有节点上各种信息通过心跳机制汇报给JobTracker。这些信息包括两部分：</p> <ul><li><p>机器级别信息：节点健康情况、资源使用情况等。</p></li> <li><p>任务级别信息：任务执行进度、任务运行状态等。</p></li></ul></li> <li><p>执行命令：JobTracker会给TaskTracker下达各种命令，主要包括：启动任务(LaunchTaskAction)、提交任务 (CommitTaskAction)、杀死任务(KillTaskAction)、杀死作业(KillJobAction)和重新初始化(TaskTrackerReinitAction)。</p></li></ol></li></ul></li></ul> <h3 id="假设hadoop一个job产生了100个task-并且其中的一个task失败了-hadoop会如何处理"><a href="#假设hadoop一个job产生了100个task-并且其中的一个task失败了-hadoop会如何处理" class="header-anchor">$</a> 假设hadoop一个job产生了100个task， 并且其中的一个task失败了，hadoop会如何处理？</h3> <p>hadoop本身的一个设计理念就是在普通的pc硬件上构建高可靠性的系统，任何failed task都不会引起整个job的失败，因为所有失败的任务都会被重新执行（reschedule     execution），只有当重新执行的次数超过4次，才会把这任务标记为失败，导致整个job的失败。</p> <h3 id="通过划分多个节点上任务-hadoop实现了并行处理-对少数慢节点可能会限制剩下其他程序的速率-并拖慢了整个程序。hadoop提供了什么机制防止这种情况的发生"><a href="#通过划分多个节点上任务-hadoop实现了并行处理-对少数慢节点可能会限制剩下其他程序的速率-并拖慢了整个程序。hadoop提供了什么机制防止这种情况的发生" class="header-anchor">$</a> 通过划分多个节点上任务，hadoop实现了并行处理，对少数慢节点可能会限制剩下其他程序的速率，并拖慢了整个程序。hadoop提供了什么机制防止这种情况的发生？</h3> <p>speculative execution。举个简单的例子，如果某个job有2000个map task，已经完成了1999个，只剩下一个task由于硬件比较慢而成为拖尾任务，为了减少拖尾任务对整个job运行时间的影响，jobtracker会重新启动一个一模一样的duplicate task和原有的task并行的执行，这样有一个task执行成功，整个map过程就会结束。speculative execution(推测执行)只有个处理拖尾任务的优化策略，并不能提高系统的可靠性</p> <h3 id="hadoop推测执行是如何实现的"><a href="#hadoop推测执行是如何实现的" class="header-anchor">$</a> hadoop推测执行是如何实现的？</h3> <p>Hadoop会为该task启动备份任务，让speculative task与原始task同时处理一份数据，哪个先运行完，则将谁的结果作为最终结果，并且在 运行完成后Kill掉另外一个任务。</p> <h3 id="unix中使用命令行-如何查看hadoop集群中的所有运行的任务-或是kill掉任务"><a href="#unix中使用命令行-如何查看hadoop集群中的所有运行的任务-或是kill掉任务" class="header-anchor">$</a> Unix中使用命令行，如何查看hadoop集群中的所有运行的任务？或是kill掉任务？</h3> <p>jps</p> <h3 id="说明hadoop2-0的基本构成"><a href="#说明hadoop2-0的基本构成" class="header-anchor">$</a> 说明hadoop2.0的基本构成</h3> <p>HDFS，MapReduce，YARN</p> <h3 id="相比于hdfs1-0-hdfs2-0最主要的改进在哪几个方面"><a href="#相比于hdfs1-0-hdfs2-0最主要的改进在哪几个方面" class="header-anchor">$</a> 相比于HDFS1.0，HDFS2.0最主要的改进在哪几个方面？</h3> <p>引入一个新的资源管理系统YARN；HDFS单点故障得以解决；Hadoop 2.0的最大变化出现在内核（HDFS、MapReduce和YARN）</p> <h3 id="试使用步骤1-步骤2-步骤3-说明yarn中运行应用程序的基本流程"><a href="#试使用步骤1-步骤2-步骤3-说明yarn中运行应用程序的基本流程" class="header-anchor">$</a> 试使用步骤1，步骤2，步骤3.……说明YARN中运行应用程序的基本流程</h3> <ol><li><p>用户向YARN中提交应用程序，其中包括ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等。</p></li> <li><p>ResourceManager为该应用程序分配第一个Container，并与对应的Node-Manager通信，要求它在这个Container中启动应用程序的 ApplicationMaster。</p></li> <li><p>ApplicationMaster首先向ResourceManager注册，这样用户可以直接通过ResourceManage查看应用程序的运行状态，然后它将为各 个任务申请资源，并监控它的运 行状态，直到运行结束，即重复步骤4~7。</p></li> <li><p>ApplicationMaster采用轮询的方式通过RPC协议向ResourceManager申请和领取资源。</p></li> <li><p>一旦ApplicationMaster申请到资源后，便与对应的NodeManager通信，要求它启动任务Task。</p></li> <li><p>NodeManager为任务Task设置好运行环境（包括环境变量、JAR包、二进制程序等）后，将任务启动命令写到一个脚本中，并通过 运行该脚本启动任务Task。</p></li> <li><p>各个任务Task通过某个RPC协议向ApplicationMaster汇报自己的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状 态，从而可以在任务失败时重新启动任务。 在应用程序运行过程中，用户可随时通过RPC向ApplicationMaster查询应用程序的当前运行状态。</p></li> <li><p>应用程序运行完成后，ApplicationMaster向ResourceManager注销并关闭自己。</p></li></ol> <h3 id="什么是mrappmaster"><a href="#什么是mrappmaster" class="header-anchor">$</a> 什么是MRAppMaster？</h3> <p>我们知道，在MRv1中，JobTracker存在诸多问题，包括存在单点故障，扩展受限等，为了解决这些问题，Apache对MRv1进行了改进，提 出了YARN，YARN将JobTracker中的作业控制和资源管理两个功能分开，分别由两个不同的进程处理，进而解决了原有JobTracker存在的问 题。经过架构调整之后，YARN已经完全不同于MRv1，它已经变成了一个资源管理平台，或者说应用程序管理框架。运行于YARN之上的计 算框架不只限于MapReduce一种，也可以是其他流行计算框架，比如流式计算、迭代式计算等类型的计算框架。为了将一个计算框架运行于 YARN之上，用户需要开发一个组件—ApplicationMaster。作为一个开始，YARN首先支持的计算框架是MapReduce，YARN为用户实现好了 MapReduce的ApplicationMaster，也就是本文要介绍了MRAppMaster。</p> <h3 id="相比于jobtracker-mrappmaster有什么不同"><a href="#相比于jobtracker-mrappmaster有什么不同" class="header-anchor">$</a> 相比于JobTracker，MRAppMaster有什么不同？</h3> <p>既然MRAppMaster是由JobTracker衍化而来的，那么是否将JobTracker的代码稍加修改，就变成了MRAppMaster呢，答案是否定的。事实 上，YARN仅重用了MRv1中的少许代码，基本可看做重写了MRAppMaster。</p> <p>YARN采用了新的软件设计思想，包括对象服务化、事件驱动的异步编程模型的。作为YARN的一部分，MRAppMaster的实现也采用了这 些设计思想。</p> <p>下面简要介绍一下MRAppMaster的实现细节：</p> <p>在正式介绍MRAppMaster之前，我们先回顾一下MRv1的实现。我们都知道，MRv1主要由两种服务组成，即：JobTracker和TaskTracker， 而在YARN中，TaskTracker已经由NodeManager代替，因此，我们在此重点分析JobTracker。JobTracker包含资源管理和作业控制两个功能， 在YARN中，作业管理由ResourceManager实现，因此，只剩下作业控制这一个功能（由MRAppMaster实现）。MRv1中每个作业由一个 JobInProgress控制，每个任务由一个TaskInProgress控制，由于每个任务可能有多个运行实例，因此，TaskInProgress实际管理了多个运行实 例Task Attempt，对于每个运行实例，可能运行了一个MapTask或者ReduceTask，另外，每个Map Task或者Reduce Task会通过RPC协议将状态 汇报给TaskTracker，再由TaskTracker进一步汇报给JobTracker 在MRAppMaster中，它只负责管理一个作业，包括该作业的资源申请、作业运行过程监控和作业容错等。MRAppMaster使用服务模型和 事件驱动的异步编程模型对JobInProgress和TaskInProgress进行了重写（分别对应JobImpl和TaskImpl），并让Map Task和Reduce Task（Map Task和Reduce Task重用了MRv1中的代码）直接通过RPC将信息汇报给MRAppMaster。此外，为了能够运行于YARN之上，MRAppMaster还要 与ResourceManager和NodeManager两个新的服务通信（用到两个新的RPC协议），以申请资源和启动任务，这些都使得MRAppMaster完全不同于JobTracker。</p> <h3 id="为什么会产生yarn-它解决了什么问题。有什么优势"><a href="#为什么会产生yarn-它解决了什么问题。有什么优势" class="header-anchor">$</a> 为什么会产生yarn,它解决了什么问题。有什么优势？</h3> <h3 id="job的运行流程"><a href="#job的运行流程" class="header-anchor">$</a> job的运行流程</h3> <p>job的执行流程如下： dataInput- &gt;split- &gt;Mapper- &gt;Combine- &gt;(产出临时数据)--&gt;Partition- &gt;Sort- &gt;Reducer- &gt;最终数据</p> <h3 id="hadoop生态圈中各种框架的运用场景"><a href="#hadoop生态圈中各种框架的运用场景" class="header-anchor">$</a> hadoop生态圈中各种框架的运用场景</h3> <h3 id="hive中的压缩格式rcfile-textfile-sequencefile各有什么区别-以上三种格式一样大的文件哪个占用空间大小"><a href="#hive中的压缩格式rcfile-textfile-sequencefile各有什么区别-以上三种格式一样大的文件哪个占用空间大小" class="header-anchor">$</a> hive中的压缩格式RCFile.TextFile.SequenceFile各有什么区别，以上三种格式一样大的文件哪个占用空间大小</h3> <p>textfile(默认) 存储空间消耗比较大，并且压缩的text 无法分割和合并 查询的效率最低,可以直接存储，加载数据的速度最高 sequencefile 存储空间消耗最大,压缩的文件可以分割和合并 查询效率高，需要通过text文件转化来加载 rcfile 存储空间最小，查询的效率最高 ，需要通过text文件转化来加载，加载的速度最低</p> <h3 id="hdfs的-client端-复制到第三个副本时宕机-hdfs怎么恢复下次写第三副本-block块信息是先写-datanode还是先写namenode"><a href="#hdfs的-client端-复制到第三个副本时宕机-hdfs怎么恢复下次写第三副本-block块信息是先写-datanode还是先写namenode" class="header-anchor">$</a> hdfs的 client端，复制到第三个副本时宕机，hdfs怎么恢复下次写第三副本？block块信息是先写 dataNode还是先写nameNode？</h3> <h3 id="在hadoop-ha集群中zookeeper-的主要作用-以及启动和查看状态的命令"><a href="#在hadoop-ha集群中zookeeper-的主要作用-以及启动和查看状态的命令" class="header-anchor">$</a> 在Hadoop HA集群中Zookeeper 的主要作用，以及启动和查看状态的命令？</h3> <h3 id="哪个程序通常与namenode在一个节点启动"><a href="#哪个程序通常与namenode在一个节点启动" class="header-anchor">$</a> 哪个程序通常与namenode在一个节点启动</h3> <p>Jobtracker</p> <p>hadoop的集群是基于master/slave模式，namenode和jobtracker属于master，datanode和tasktracker属于slave，master只有一个，而slave有多个
SecondaryNameNode内存需求和NameNode在一个数量级上，所以通常secondary NameNode（运行在单独的物理机器上）和NameNode运行在不同的机器上。
JobTracker对应于NameNode，TaskTracker对应于DataNode
DataNode和NameNode是针对HDFS数据存放来而言的，JobTracker和TaskTracker是对于MapReduce执行而言的</p> <p>mapreduce中几个主要概念，mapreduce整体上可以分为这么几条执行线索：jobclient，JobTracker与TaskTracker。
(1)、JobClient会在用户端通过JobClient类将应用已经配置参数打包成jar文件存储到hdfs，
并把路径提交到Jobtracker,然后由JobTracker创建每一个Task（即MapTask和ReduceTask）并将它们分发到各个TaskTracker服务中去执行
(2)、JobTracker是一个master服务，软件启动之后JobTracker接收Job，负责调度Job的每一个子任务task运行于TaskTracker上，
并监控它们，如果发现有失败的task就重新运行它。一般应该把JobTracker部署在单独的机器上。
(3)、TaskTracker是运行在多个节点上的slaver服务。TaskTracker主动与JobTracker通信，接收作业，并负责直接执行每一个任务。
TaskTracker都需要运行在HDFS的DataNode上</p> <h3 id="hive中的压缩格式rcfile、textfile、sequencefile各有什么区别"><a href="#hive中的压缩格式rcfile、textfile、sequencefile各有什么区别" class="header-anchor">$</a> hive中的压缩格式RCFile、TextFile、SequenceFile各有什么区别？</h3> <p><strong>textfile</strong> 文件存储就是正常的文本格式，将表中的数据在hdfs上 以文本的格式存储，下载后可以直接查看，也可以使用cat命令查看。</p> <p>指定方式：</p> <ol><li>默认无需指定</li> <li>显示指定stored as textfile</li> <li>显示指定
STORED AS INPUTFORMAT
'org.apache.hadoop.mapred.TextInputFormat'
OUTPUTFORMAT           'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'</li></ol> <p>优点弊端：</p> <ol><li>行存储使用textfile存储文件默认每一行就是一条记录，</li> <li>可以使用任意的分隔符进行分割。</li> <li>但无压缩，所以造成存储空间大。可结合Gzip、Bzip2、Snappy等使用（系统自动检查，执行查询时自动解压），但使用这种方式，hive不会对数据进行切分，从而无法对数据进行并行操作。</li></ol> <p><strong>sequencefile</strong> 在hdfs上将表中的数据以二进制格式编码，并且将数据压缩了，下载数据以后是二进制格式，不可以直接查看，无法可视化。</p> <p>指定方式：</p> <ol><li>stored as sequecefile</li> <li>或者显示指定：
STORED AS INPUTFORMAT
'org.apache.hadoop.mapred.SequenceFileInputFormat'
OUTPUTFORMAT
'org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat'</li></ol> <p>优点弊端：</p> <ol><li>sequencefile存储格有压缩，存储空间小，有利于优化磁盘和I/O性能</li> <li>同时支持文件切割分片，提供了三种压缩方式：none,record,block（块级别压缩效率跟高）.默认是record(记录)</li></ol> <p><strong>rcfile</strong> 在hdfs上将表中的数据以二进制格式编码，并且支持压缩。下载后的数据不可以直接可视化。</p> <p>指定方式：</p> <ol><li>stored as rcfile</li> <li>或者显示指定：
STORED AS INPUTFORMAT
'org.apache.hadoop.hive.ql.io.RCFileInputFormat'
OUTPUTFORMAT
'org.apache.hadoop.hive.ql.io.RCFileOutputFormat'</li></ol> <p>优点弊端：</p> <ol><li>行列混合的存储格式，基于列存储。</li> <li>因为基于列存储，列值重复多，所以压缩效率高。</li> <li>磁盘存储空间小，io小。</li></ol> <h3 id="namenode与secondarynamenode的区别与联系"><a href="#namenode与secondarynamenode的区别与联系" class="header-anchor">$</a> NameNode与SecondaryNameNode的区别与联系？</h3> <h3 id="mapreduce出现单点负载多大-怎么负载平衡"><a href="#mapreduce出现单点负载多大-怎么负载平衡" class="header-anchor">$</a> MapReduce出现单点负载多大，怎么负载平衡？</h3> <h3 id="mapreduce怎么实现top10"><a href="#mapreduce怎么实现top10" class="header-anchor">$</a> MapReduce怎么实现Top10？</h3> <h3 id="在hadoop开发过程中使用过哪些算法-其应用场景是什么"><a href="#在hadoop开发过程中使用过哪些算法-其应用场景是什么" class="header-anchor">$</a> 在hadoop开发过程中使用过哪些算法？其应用场景是什么？</h3> <h3 id="mapreduce程序如何发布-如果mapreduce中涉及到了第三方的jar-包-该如何处理"><a href="#mapreduce程序如何发布-如果mapreduce中涉及到了第三方的jar-包-该如何处理" class="header-anchor">$</a> MapReduce程序如何发布？如果MapReduce中涉及到了第三方的jar 包，该如何处理？</h3> <h3 id="在实际工作中使用过哪些集群的运维工具-请分别阐述其作用。"><a href="#在实际工作中使用过哪些集群的运维工具-请分别阐述其作用。" class="header-anchor">$</a> 在实际工作中使用过哪些集群的运维工具，请分别阐述其作用。</h3> <h3 id="fsimage和edit的区别"><a href="#fsimage和edit的区别" class="header-anchor">$</a> fsimage和edit的区别？</h3> <h3 id="比方-如今有10个文件夹-每个文件夹都有1000000个url-如今让你找出top1000000url。"><a href="#比方-如今有10个文件夹-每个文件夹都有1000000个url-如今让你找出top1000000url。" class="header-anchor">$</a> 比方:如今有10个文件夹, 每个文件夹都有1000000个url. 如今让你找出top1000000url。</h3> <p>方法一：
运用2个job，第一个job直接用filesystem读取10个文件夹作为map输入，url做key，reduce计算url的sum，
下一个job map用url作key，运用sum作二次排序，reduce中取top10000000</p> <p>方法二：
建hive表A，挂分区channel，每个文件夹是一个分区.
select x.url,x.c from(select url,count(1) as c from A where channel ='' group by url) x order by x.c desc limit 1000000;</p> <h3 id="关于secondarynamenode哪项是正确的"><a href="#关于secondarynamenode哪项是正确的" class="header-anchor">$</a> 关于SecondaryNameNode哪项是正确的？</h3> <p>a)它是NameNode的热备 b)它对内存没有要求
c)它的目的是帮助NameNode合并编辑日志，减少NameNode启动时间
d)SecondaryNameNode应与NameNode部署到一个节点
答案C。</p> <h3 id="client-端上传文件的时候下列哪项正确"><a href="#client-端上传文件的时候下列哪项正确" class="header-anchor">$</a> Client 端上传文件的时候下列哪项正确</h3> <p>a)数据经过 NameNode 传递给 DataNode
b)Client端将文件切分为Block，依次上传
c)Client只上传数据到一台DataNode，然后由NameNode负责Block复制工作
答案：B
分析：
Client向NameNode发起文件写入的请求。NameNode根据文件大小和文件块配置情况，返回给Client它所管理部分DataNode的信息。
Client将文件划分为多个Block，根据DataNode的地址信息，按顺序写入到每一个DataNode块中。</p> <h3 id="namenode-负责管理-metadata-client-端每次读写请求-它都会从磁盘中读取或则会写入-metadata-信息并反馈-client-端。-错误"><a href="#namenode-负责管理-metadata-client-端每次读写请求-它都会从磁盘中读取或则会写入-metadata-信息并反馈-client-端。-错误" class="header-anchor">$</a> NameNode 负责管理 metadata，client 端每次读写请求，它都会从磁盘中读取或则会写入 metadata 信息并反馈 client 端。（错误）</h3> <p>分析：
NameNode 不需要从磁盘读取 metadata，所有数据都在内存中，硬盘上的只是序列化的结果，只有每次 namenode 启动的时候才会读取。
(1) 文件写入
Client向NameNode发起文件写入的请求。
NameNode根据文件大小和文件块配置情况，返回给Client它所管理部分DataNode的信息。
Client将文件划分为多个Block，根据DataNode的地址信息，按顺序写入到每一个DataNode块中。</p> <p>(2) 文件读取
Client向NameNode发起文件读取的请求。
NameNode返回文件存储的DataNode的信息。
Client读取文件信息。</p> <h3 id="namenode-本地磁盘保存了-block-的位置信息。-正确"><a href="#namenode-本地磁盘保存了-block-的位置信息。-正确" class="header-anchor">$</a> NameNode 本地磁盘保存了 Block 的位置信息。（正确）</h3> <p>分析：
DataNode是文件存储的基本单元，它将Block存储在本地文件系统中，保存了Block的Meta-data，同时周期性地将所有存在的Block信息发送给NameNode。</p> <h3 id="datanode-通过长连接与-namenode-保持通信。"><a href="#datanode-通过长连接与-namenode-保持通信。" class="header-anchor">$</a> DataNode 通过长连接与 NameNode 保持通信。</h3> <p>这个有分歧，首先明确一下概念：
(1) 长连接
Client方与Server方先建立通讯连接，连接建立后不断开，然后再进行报文发送和接收。这种方式下由于通讯连接一直存在，此种方式常用于点对点通讯。</p> <p>(2) 短连接
Client方与Server每进行一次报文收发交易时才进行通讯连接，交易完毕后立即断开连接。此种方式常用于一点对多点通讯，比如多个Client连接一个Server.</p> <h3 id="hadoop-自身具有严格的权限管理和安全措施保障集群正常运行。-错误"><a href="#hadoop-自身具有严格的权限管理和安全措施保障集群正常运行。-错误" class="header-anchor">$</a> Hadoop 自身具有严格的权限管理和安全措施保障集群正常运行。（错误）</h3> <p>hadoop只能阻止好人犯错，但是不能阻止坏人干坏事</p> <h3 id="slave-节点要存储数据-所以它的磁盘越大越好。-错误"><a href="#slave-节点要存储数据-所以它的磁盘越大越好。-错误" class="header-anchor">$</a> Slave 节点要存储数据，所以它的磁盘越大越好。（错误）</h3> <p>分析：
一旦Slave节点宕机，数据恢复是一个难题</p> <h3 id="hadoop-dfsadmin-report-命令用于检测-hdfs-损坏块。-错误"><a href="#hadoop-dfsadmin-report-命令用于检测-hdfs-损坏块。-错误" class="header-anchor">$</a> hadoop dfsadmin –report 命令用于检测 HDFS 损坏块。（错误）</h3> <p>分析：
hadoop dfsadmin -report
用这个命令可以快速定位出哪些节点down掉了，HDFS的容量以及使用了多少，以及每个节点的硬盘使用情况。</p> <h3 id="hadoop-默认调度器策略为-fifo-正确"><a href="#hadoop-默认调度器策略为-fifo-正确" class="header-anchor">$</a> Hadoop 默认调度器策略为 FIFO（正确）</h3> <h3 id="集群内每个节点都应该配-raid-这样避免单磁盘损坏-影响整个节点运行。-错误"><a href="#集群内每个节点都应该配-raid-这样避免单磁盘损坏-影响整个节点运行。-错误" class="header-anchor">$</a> 集群内每个节点都应该配 RAID，这样避免单磁盘损坏，影响整个节点运行。（错误）</h3> <p>分析：
首先明白什么是RAID，可以参考百科磁盘阵列。这句话错误的地方在于太绝对，具体情况具体分析。题目不是重点，知识才是最重要的。因为hadoop本身就具有冗余能力，所以如果不是很严格不需要都配备RAID。具体参考第二题。</p> <h3 id="因为-hdfs-有多个副本-所以-namenode-是不存在单点问题的。-错误"><a href="#因为-hdfs-有多个副本-所以-namenode-是不存在单点问题的。-错误" class="header-anchor">$</a> 因为 HDFS 有多个副本，所以 NameNode 是不存在单点问题的。（错误）</h3> <p>分析：
NameNode存在单点问题。了解详细信息，可以参考
Hadoop中Namenode单点故障的解决方案及详细介绍AvatarNode</p> <h3 id="mapreduce-的-input-split-就是一个-block。-错误"><a href="#mapreduce-的-input-split-就是一个-block。-错误" class="header-anchor">$</a> Mapreduce 的 input split 就是一个 block。（错误 ）</h3> <p>InputFormat的数据划分、Split调度、数据读取三个问题的浅析​</p> <h3 id="datanode-首次加入-cluster-的时候-如果-log-中报告不兼容文件版本-那需要namenode执行-hadoop-namenode-format-操作格式化磁盘。-错误"><a href="#datanode-首次加入-cluster-的时候-如果-log-中报告不兼容文件版本-那需要namenode执行-hadoop-namenode-format-操作格式化磁盘。-错误" class="header-anchor">$</a> DataNode 首次加入 cluster 的时候，如果 log 中报告不兼容文件版本，那需要NameNode执行“Hadoop namenode -format”操作格式化磁盘。（错误 ）</h3> <p>分析：
这个报错是说明DataNode所装的Hadoop版本和其它节点不一致，应该检查DataNode的Hadoop版本</p> <h3 id="hive如何调优"><a href="#hive如何调优" class="header-anchor">$</a> hive如何调优？</h3> <h3 id="hive如何权限控制"><a href="#hive如何权限控制" class="header-anchor">$</a> hive如何权限控制？</h3> <h3 id="hbase写数据的原理是什么"><a href="#hbase写数据的原理是什么" class="header-anchor">$</a> hbase写数据的原理是什么？</h3> <h3 id="hive能像关系数据库那样-建多个库吗"><a href="#hive能像关系数据库那样-建多个库吗" class="header-anchor">$</a> hive能像关系数据库那样，建多个库吗？</h3> <h3 id="hbase宕机如何处理"><a href="#hbase宕机如何处理" class="header-anchor">$</a> hbase宕机如何处理？</h3> <h3 id="hive实现统计的查询语句是什么"><a href="#hive实现统计的查询语句是什么" class="header-anchor">$</a> hive实现统计的查询语句是什么？</h3> <h3 id="生产环境中为什么建议使用外部表"><a href="#生产环境中为什么建议使用外部表" class="header-anchor">$</a> 生产环境中为什么建议使用外部表？</h3> <h3 id="hadoop-mapreduce创建类datawritable的作用是什么"><a href="#hadoop-mapreduce创建类datawritable的作用是什么" class="header-anchor">$</a> hadoop mapreduce创建类DataWritable的作用是什么？</h3> <h3 id="为什么创建类datawritable"><a href="#为什么创建类datawritable" class="header-anchor">$</a> 为什么创建类DataWritable？</h3> <h3 id="用mapreduce实现sql语句select-count-x-from-a-group-by-b"><a href="#用mapreduce实现sql语句select-count-x-from-a-group-by-b" class="header-anchor">$</a> 用mapreduce实现sql语句select count(x) from a group by b？</h3> <h3 id="sqoop在导入数据到mysql时-如何让数据不重复导入-如果存在数据问题sqoop如何处理"><a href="#sqoop在导入数据到mysql时-如何让数据不重复导入-如果存在数据问题sqoop如何处理" class="header-anchor">$</a> sqoop在导入数据到mysql时，如何让数据不重复导入？如果存在数据问题sqoop如何处理？</h3> <h3 id="描述一下hadoop中-有哪些地方使用了缓存机制-作用分别是什么"><a href="#描述一下hadoop中-有哪些地方使用了缓存机制-作用分别是什么" class="header-anchor">$</a> 描述一下hadoop中，有哪些地方使用了缓存机制，作用分别是什么？</h3> <h3 id="用mapreduce怎么处理数据倾斜问题"><a href="#用mapreduce怎么处理数据倾斜问题" class="header-anchor">$</a> 用mapreduce怎么处理数据倾斜问题？</h3> <p>map /reduce程序执行时，reduce节点大部分执行完毕，但是有一个或者几个reduce节点运行很慢，导致整个程序的处理时间很长，这是因为某一个key的条数比其他key多很多（有时是百倍或者千倍之多），这条key所在的reduce节点所处理的数据量比其他节点就大很多，从而导致某几个节点迟迟运行不完，此称之为数据倾斜。</p> <p>用hadoop程序进行数据关联时，常碰到数据倾斜的情况，这里提供一种解决方法。</p> <p>(1)设置一个hash份数N，用来对条数众多的key进行打散。</p> <p>(2)对有多条重复key的那份数据进行处理：从1到N将数字加在key后面作为新key，如果需要和另一份数据关联的话，则要重写比较类和分发类（方法如上篇<a href="https://www.baidu.com/s?wd=%E3%80%8Ahadoop%C2%A0job%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%87%8F%E5%85%B3%E8%81%94%E7%9A%84%E4%B8%80%E7%A7%8D%E6%96%B9%E6%B3%95%E3%80%8B&amp;tn=24004469_oem_dg&amp;rsv_dl=gh_pl_sl_csd" target="_blank" rel="noopener noreferrer">《hadoop job解决大数据量关联的一种方法》<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>）。如此实现多条key的平均分发。</p> <p>int iNum = iNum % iHashNum;</p> <p>String strKey = key + CTRLC + String.valueOf(iNum) + CTRLB + “B”;</p> <p>（3）上一步之后，key被平均分散到很多不同的reduce节点。如果需要和其他数据关联，为了保证每个reduce节点上都有关联的key，对另一份单一key的数据进行处理：循环的从1到N将数字加在key后面作为新key</p> <p>for(int i = 0; i &lt; iHashNum; ++i){</p> <p>String strKey =key + CTRLC + String.valueOf(i) ;</p> <p>output.collect(new Text(strKey), new Text(strValues));}</p> <p>以此解决数据倾斜的问题，经试验大大减少了程序的运行时间。但此方法会成倍的增加其中一份数据的数据量，以增加shuffle数据量为代价，所以使用此方法时，要多次试验，取一个最佳的hash份数值。</p> <p>======================================</p> <p>用上述的方法虽然可以解决数据倾斜，但是当关联的数据量巨大时，如果成倍的增长某份数据，会导致reduce shuffle的数据量变的巨大，得不偿失，从而无法解决运行时间慢的问题。</p> <p>有一个新的办法可以解决 成倍增长数据 的缺陷：</p> <p>在两份数据中找共同点，比如两份数据里除了关联的字段以外，还有另外相同含义的字段，如果这个字段在所有log中的重复率比较小，则可以用这个字段作为计算hash的值，如果是数字，可以用来模hash的份数，如果是字符可以用hashcode来模hash的份数（当然数字为了避免落到同一个reduce上的数据过多，也可以用hashcode），这样如果这个字段的值分布足够平均的话，就可以解决上述的问题。-</p> <p>\48. 毒酒问题－－－1000桶酒，其中1桶有毒，而一旦吃了，毒性会在一周后发作。问最少需要多少只 老鼠可在一周内找出毒酒？</p> <p>\49. 用栈实现队列？</p> <p>\50. 链表倒序实现？</p></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">更新时间:</span> <span class="time">8/29/2020, 2:45:20 AM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/bigdata/zookeeper/isbn9787111524311_note.html" class="prev">
        《ZooKeeper分布式过程协同技术详解》笔记
      </a></span> <span class="next"><a href="/bigdata/hadoop/port.html">
        Hadoop默认端口
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"><!----></div></div>
    <script src="/assets/js/app.e1b640f1.js" defer></script><script src="/assets/js/2.f106ac60.js" defer></script><script src="/assets/js/53.24880467.js" defer></script>
  </body>
</html>
